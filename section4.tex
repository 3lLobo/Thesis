This section describes the methodology for this thesis. The first part includes the presentation of the model, the reprocessing of the input and the evaluation metrics. The second part describes the experimental setup and the different experimental runs. The work of this thesis has aimed to be fully reproducable, thus the code is opensourced and available on Github \footnote{***Thesis Repo***}.

\subsection{Knowledge graph representation}

adjacency matrix
edge attribute matrix
node attribute matrix

Graph embeddings? unsupervised approach

\subsection{Graph VAE}

\\Convolution part
\\RCGN relation Convolution neural net
\\MLP encoder
\\Latent space
\\reparametrization trick
\\MLP decoder
\\Graph matching
\\Discretization of prediction

\subsection{Loss function}

If loss function should be permutaion invariant we need to do some kind of graph matching.\\
Different options for graph matching.\\
Maxpooling-algorithm:\\
Assumptions\\
Node to edge affinity equals 0
Summing over the neighbors means summing over the whole column

Hungarian algorighm for discretization of X
\\
second option:
Compare only graph structure. 
NX algorithms: Greedy, Shortest path \dots

\subsection{Metrics}

WHAAAA O.o
Link prediction?