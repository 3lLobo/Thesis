
TODO

Here comes a beautiful introduction. %Promise!


\subsection{Motivation}

Computer vision reached a point, where semantics, entities and relations can be inferred in an simple image.
Would it not be fantastic if we be able to apply this to text too?
Could we possibly learn a model to understand the semantics of a KG?



% A key goal of representation learning is to identify and disentangle the underlying causal factors of
% the data, so that it becomes easier to understand the data, to classify it, or to perform other tasks
% (Bengio et al., 2013). For image data this often means that we are interested in uncovering the
% “global structure” that captures the content of an image (for example, the identity of objects present
% in the image) and its “style”, but that we are typically less interested in the local and high frequency
% sources of variation such as the specific textures or white noise patterns.

\subsection{Expected Contribution}

This thesis is aimed to be a proof of concept, providing insight into the capability of the VAE on generating KG triples and to indicate if further research in this direction would be meaningful.

\subsection{Research Question}

\texttt{Can a VAE learn the underlying semantics of a KG?}


Without further ado -
