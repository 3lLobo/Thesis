This section describes the methods used in the experiments of this thesis. We will begin with data formatting and preprocessing, then the presentation the model, mainly the encoder and decoder and their variations. Moving on we explain our implementation of graph matching the loss function of the model and its evaluation metrics. To the end of this chapter we describe the link prediction pipeline which is the main experiment to evaluate our model. Our implementation is written in Python using PyTorch, a high-performance deep-learning library \cite{paszke_pytorch_2019}. All experiments are aimed to be fully reproducible and the model meant to be used in future work, thus the code is openly available on Github \footnote{\url{https://github.com/INDElab/rgvae}}.

\subsection{Knowledge graph data}
All our presented methods will operate on KG data. While data from other graph domains is possible, this work focuses solely on datasets in triple format. We will explain the sparse graph representation, which is the input format for our model and how to preprocess the original KG triples to match that format.

\subsubsection{Sparse representation}

% The first step in our pipeline is the representation of the KG in tensor format. In order to represent the graph structure we use an adjacency matrix $A$ of shape $n\times n$ with $n$ being the number of nodes in our graph. The edge attribute or directed relations between the nodes are represented in the matrix $E$ of shape $n\times n\times d_E$ with $d_E$ being the number of edge attributes. Similarly for node attributes we have the matrix $F$ of shape $n\times d_N$ with $d_N$ number of node attributes. The input graph can have less nodes than the maximum $n$ but not more. The diagonal of the adjacency matrix is filled with $1$ if the indexed node exists, and with $0$ otherwise. The number and encoding of the attributes must be predefined and cannot be changed after training. This way we can uniquely represent a KG.

In this work, we opt for the sparse graph representation $G(A,E,F)$, where $A$ denotes the adjacency matrix, $E$ the edge feature matrix and $F$ the node feature matrix. This allows models architectures as discussed in \ref{ssec:GVAE}. The graph is binary and each matrix is stored in a separate tensor.

% adjacency matrix
The adjacency matrix $A$ takes the shape $(n\times n)$ with $n$ being the number of nodes in our graph/subgraph. While most of previous work would only allow edges on the upper triangular adjacency matrix and fill the diagonal with ones, we chose a less constrained representation, which we assume is a better fit for representing KGs. In particular, we allow self-loops, meaning a triple where object and subject are the same entity and our relations are directed and can be inverted. Thus $A$ can have a positive signal at any position $A_{i,j}$  $i,j \in \mathbb{R}^{n \times n}$, indicating a directed edge between node of index $i$ and node of index $j$, while $A_{i,j}$ differs from $A_{j,i}$.

% edge attribute matrix
The edge attribute matrix $E$ takes the shape $(n\times n\times d_e)$ with $d_e$ being the number of unique entities in our dataset. For each possible edge in the adjacency matrix we have a one hot encoded vector pointing to the unique relation in the dataset. Stacking these vectors leads to the three dimensional matrix $E$.

% node attribute matrix
The shape of node attributes matrix $F$ is $(n\times d_e)$ with $d_e$ being the number of node attributes describing the nodes. Considering that we will split the KG in subgraphs, we use the entity index as node attribute, making it possible to assign every node in a subgraph to the entity in the full KG. Thus, the number of node attributes $d_e$ equals the number unique entities in our dataset. Again the node attributes are one hot encoded vectors, which stacked result in the two dimensional $F$ matrix.


\subsubsection{Preprocessing}
Our datasets consist of three tab separated value files full of triples for training, validation and testing. The preprocessing steps do not only account for generating subgraphs in the right format, but also ensure valuable research by withholding the triples from the test set until the final run.

% set of entities, set of relations 
% triple to graph
% all triples
% true triples dict
% indexing
From all three sets, we create a set of all occurring entities and similar set for the relations. Now we can define our dimensions $d_e$ and $d_r$. For both sets we create two dictionaries \textit{index-2-entity} and \textit{entity-2-index}  which map back and forth between numerical index and the string representation of the entity (similar for the relation set). These dictionaries are used to create a train and test set of triples with numeric indices. Depending if we are in the final testing stage or not, we include all triples from the training and evaluation file in the training set and use the triples in the testing file as test set, or we ignore the triples in the test file and use the evaluation file triples as test set.

%  truetriples dict 
Further we create two dictionaries, \textit{head} and \textit{tail} which for all occurring subject and relation combination, contain all entities which would complete it to a real triple in our dataset (similar for all relation and object combinations). This will allows us to filter true triples, which reduces the score bias for link prediction and evaluates the ratio of unseen triples for graph generation. 

%  triple 2 graph
The final step of preprocessing is a function, which takes a batch of numerical triples and converts them to a batch of binary, multidimensional tensors $A$, $E$ and $F$. While this might sound easy for only one triple per graph, it proves more complex for graphs with $n>2$ facing exemption cases such as self loops or an entity occurring in two triples. We solve this by creating a separate set for head and tail entities, then storing the indices of both in a list, starting with the subject set and finally using this list as keys for a dictionary with values in the range to $n$. In both edge cases, this results in an adjacency matrix with a rank lower than $n$. A similar approach, with less edge cases to consider, is used to apply the inverted translation from tensor matrix to triple.

% Graph embeddings? unsupervised approach

\subsection{RGVAE}
The principle of a graph VAE has been explained in \ref{ssec:GVAE}, which also covers the foundation of our model, the Relational Graph VAE (RGVAE). Therefore we will focus on the implementation as well as parameter and hyperparameter choice. Since this work is meant to be a prove of concept rather than aimed at outperforming the state of the art, our model is kept as simple as possible and only as complex as necessary. Our approach is module based for both experiment pipeline and model, meaning independence between sequential modules and compatibility with parallel modules. For the encoder we implemented two variations, a fully connected and a convolutional, while for the decoder we opted for a single fully connected network.
%  just explain the code

\subsubsection{Initialization}

The RGVAE is initialized with a set of hyperparameter, which define the input shape. Table \ref{tab:RGVAEhyp} shows a complete list of those parameters and their default values. It is left to mention that we use the Xavier uniform initialization with a gain of $0,01$ to initialize the parameters \cite{glorot2010understanding}.

\begin{table}[H]
\centering
    \begin{tabular}{|l|l|l|}
    \hline
    \rowcolor[HTML]{EFEFEF}
    \multicolumn{1}{|c}{\textsc{Hyerp.}} & \multicolumn{1}{c}{\textsc{Default}} & \multicolumn{1}{c|}{\textsc{Description}} \\\hline
    $n$     & \multicolumn{1}{c|}{$2$} & Number of nodes  \\
    $d_e$   &\multicolumn{1}{c|}{-}   & Total number of entities\\
    $d_r$   &\multicolumn{1}{c|}{-} & Total number of relations\\
    $d_z$ &\multicolumn{1}{c|}{$100$}   & Latent space dimension\\
    $d_h$ &\multicolumn{1}{c|}{$512$}   & Hidden dimension\\
    $dropout$ &\multicolumn{1}{c|}{$0.2$}   & Dropout\\
    $\beta$ & \multicolumn{1}{c|}{$1$}  & $\beta$ value for regularization  \\
    $perminv$ & \multicolumn{1}{c|}{\textbf{True}}  & Permutation invariant loss function  \\
    $clipgrad$ & \multicolumn{1}{c|}{\textbf{True}}  & Learning w/ gradient clipping  \\
    $encoder$ & \multicolumn{1}{c|}{\textbf{MLP}}  & Choice of encoder architecture  \\
    \hline
    \end{tabular}
    \caption{The initial hyperparameter of the RGVAE with default value and description.}
    \label{tab:RGVAEhyp}
\end{table}


\subsubsection{Encoder}
% \\Convolution part
% \\RCGN relation Convolution neural net
% \\MLP encoder
% \\Latent space
% \\reparametrization trick
% \\MLP decoder
% \\Graph matching
% \\Discretization of prediction

% MLP
The prove-of-concept encoder is a MLP as described in \ref{ssec:mlp}, which takes the flattened concatenated threefold graph $x=G(A,E,F)$ as batch input. We use the initial parameters to calculate the input

\begin{equation}
    d_{input} = n\times n + n\times n\times d_r + n\times d_e
    \label{eq4:inputdim}
\end{equation}

The main encoder architecture is a 3 layer fully connected network, with both layers using ReLU as activation function. The choice for two hidden layers is based on the huge difference between $d_{input}$ and $d_z$. The first layer has a dimension of $2*d_h$ and the option to use dropout, which by default is set to $0.2$. The second (hidden) layer has the dimension $d_h$ which is by default set to $1024$. After the second ReLU activation, the encoder linearly transforms the hidden state to an output vector of $2 \times d_z$. This vector is split and makes the mean and log-variance of size $d_z$ for the reparametrization trick. Sampling $\epsilon$ from an autonomous module, we get the latent representation $z$ of $x$,  the final output of the encoder.

% % Convolutions
The second option for our RGVAE encoder is a GCN as described in \ref{ssec:gcn}. We adopt the architecture from \cite{kipf_semi-supervised_2017} namely two layers of graph convolutions with dropout in between. To match the encoder output to the base model, we then add a flattening and a final linear transformation layer. To substitute the feature matrix used in Kipf's work, we reduce the edge attribute matrix $E$ by one dimension and concatenate it with $F$ resulting in $x_{GCN} \in \mathbb{R}^{n \times (d_e+n*d_r)}$. The forward pass of the adjacency matrix $A$ and $x_{GCN}$ through the first GCN layer with a hidden dimension of $d_h$ and ReLU as activation function is followed by a dropout layer. It should be mentioned that dropout is only applied during learning, not on evaluation. The second GCN layer takes the output from the previous layer, the two dimesntional hidden state and again $A$ as input. Now, instead of having the GCN predict on a number of classes, we use it to output a logits vector of dimension $2\timesd_z$. Therefore we pass the GCN output through a flattening and a linear transformation layer. Similar to the above described encoder we use the reparametrization trick to output the latent reparametrization $z$. Table \ref{tab4:archcompare} shows the two encoder architectures side by side.


\begin{table}[H]
    \centering
        \begin{tabular}{|l|l|}
        \hline
        \rowcolor[HTML]{EFEFEF}
        \multicolumn{1}{|c}{\textsc{MLP}} & \multicolumn{1}{c}{\textsc{Graph Conv.}} \\\hline
        Flatten($d_{input}$) &   Concatenate \\
        Linear($d_{input},d_{h}\times 2$) &   Convolution($A,X$) \\
        ReLu() &   ReLU() \\   
        Dropout($0.2$) &   Dropout($0.2$) \\
        Linear($d_{h}\times 2,d_{h}$) &   Convolution($H^{(1)},X$) \\
        ReLu() &   Flatten \\
        Linear($d_{h},d_{z}$) &   Linear($d_{H^{(1)}},d_z$) \\
        \hline
        \end{tabular}
        \caption{Comparison of the two variants for the encoder of the RGVAE.}
        \label{tab4:archcompare}
    \end{table}

\subsubsection{Decoder}


For our RGVAE decoder, we use the same minimal approach as in \cite{simonovsky_graphvae_2018}, namely an MLP with inverted dimensions. The decoder architecture is similar with inverse dimensions to the MPL encoder described in \ref{tab4:archcompare}. Since we are decoding the latent space, the input dimension is $d_z$ and the output dimension is $d_{input}$ as calculated in equation \ref{eq4:inputdim}. The flat logits output tensor is split threefold and reshaped to the original input shape of $G(A,E,F)$.   



To sample from the generated graph we apply the Sigmoid activation function to the logits prediction for the adjacency matrix and use the normalized output as weights for binomial distributions, from which we can sample the discrete $\tilde{A}$. For $\tilde{E}$ and $\tilde{F}$ we take the argmax on the last dimension of both matrices. Each node and edge can have only one attribute, referring to its index in $\mathcal{E}$ and $\mathcal{V}$, thus only the highest predicted value is relevant. The generated sample is a discrete graph $\tilde{G}(\tilde{A},\tilde{E},\tilde{F})$.


\subsubsection{Limitations}

The main limitation of the RGVAE is the parabolic increase of model parameters with the increase of nodes per input graph $\mathcal{O}(n^2)$. The number of parameters to train is directly linked with the GPU memory requirements. Even more computationally expensive is the use of permutation invariant graph matching, with a complexity of $\mathcal{O}(n^3)$. Thus, we propose this model only for generating small graphs with $n<30$.


% The proposed model is expected to be useful
% only for generating small graphs. This is due to growth
% of GPU memory requirements and number of parameters
% (O(k
% 2
% )) as well as matching complexity (O(k
% 4
% )), with small
% decrease in quality for high values of k. I
% \cite{simonovsky_graphvae_2018}


% \subsubsection{Hyperparameters}
% learning rate
% beta for regularization term
% hidden dimensions
% latent dimensions
% dropout
% n, d_e, d_r
% Convolutions vs no convolutions
% IDEA: Convolutions + MLP


\subsection{RGVAE learning}
% Lay out pipeline.

In this section we will present our implementation of how to fit the model to the data. Learning a model on data is a mostly standardized procedure, which includes training and evaluation per epoch. During training, the model forward passes the data, computes the loss, then does a backwards pass and updates its parameters. During evaluation, it is presented a split of the dataset unseen during training. Only the forward pass is done and the loss tracked during evaluation. Up to this point the RGVAE does not differ from the vanilla VAE training. Special is the graph matching function which is applied to the predicted graph and the loss function which takes into account the optimal permutation. Thus, we will look deeper into graph matching and derive RGVAE loss.
The training and all experiments are performed on the GPU cluster LISA of the supercomputer SURFsara on the Dutch national e-infrastructure with the support of SURF Cooperative \cite{fengvaleriu}. Each GPU node is powered by a Nvidia titan RX 25GB. We log our experiments and results using \textit{Weights & Biases}, a cloud-based experiment tracking tool \cite{wandb}.



% GPU requirements.
% LISA
% Nvidia titan RX 25GB 60h
% Experiment log wndb.ai [cite]
% optimizer ranger github repo link

\subsubsection{Max pooling graph matching}

While the pseudocode presented in \cite{cho_finding_2014} is simple and straightforward, it proves complicated to implement this in algorithms for batches and thus, without looping over the indices. Yet, our batch implementation solves these challenges and is more efficient than the direct implementation, which we use for validating our results. Given the target graph $G$ and the predicted graph $\tilde{G}$, the algorithm can be divided in three steps, calculating the five dimensional affinity matrix (the first being the batch dimension), max-pool matching the soft (continuous) similarity matrix $X^*$ and discretizing $X^*$ to our final permutation matrix $X$.

% Affinity
We use equation \ref{eq3:s} for the first step but instead of adding the two terms to a single output, we return $S$ twofold as $S_r$, five dimensional holding the information of edge affinity and $S_e$, three dimensional with the affinity information of the nodes. In a preprocessing step we zero out the diagonal of $A$, $\tilde{A}$ and for $E$ and $\tilde{E}$ the diagonal of the second and third dimension, to compile with the constrain $[i \neq j \wedge a \neq b]$ of the first term. For the second term we only take into account the diagonal of $\tilde{A}$ to compile with the constrain $[i=j \wedge a=b]$. Pseudocode \ref{alg4:s} shows the implementation, here \textit{diag()} stands for a vector with only the diagonal entries. For the dot product of $E$ and $\tilde{E}$ over the last dimension we implement our own version of \texttt{torch.matmul()} to cope with higher dimensions. The operator $\odot$ denotes element-wise matrix multiplication.



\begin{algorithm}[H]
    \caption{Batch implementation for the affinity between two graphs }
    \hspace*{\algorithmicindent} \textbf{Input:} $G(A,E,F$ and $\tilde{G}(\tilde{A},\tilde{E},\tilde{F})$
    \begin{algorithmic}[1]
        % \Input{$G(A,E,F$ and $\tilde{G}(\tilde{A},\tilde{E},\tilde{F})$}
        \Statex \textbf{First term:} $[i \neq j \wedge a \neq b]$
        \State $E_{term1} = E^T  \tilde{E}$ \Comment{Dot product over the last dimension}
        \State $A_{term1} = A\operatorname{.unsqueeze}(-1)^T (\tilde{A} \odot (\tilde{A}  \tilde{A}^T))\operatorname{.unsqueeze}(-1)$ \Comment{Dot product over the last (empty) dimension}
        \State $S_r = E_{term1} \odot A_{term1}$
        \Statex \textbf{Second term:} $[i=j \wedge a=b]$
        \State $A_{term2} = \operatorname{ones\_like}(\operatorname{diag}(\tilde{A}))^T \operatorname{diag}(\tilde{A})$
        \State $F_{term2} = F^T  \tilde{F}$ \Comment{Dot product over the last dimension}
        \State $S_e = F_{term2} \odot A_{term2}$
        \State \textbf{return} $(S_r, S_e)$
    \end{algorithmic}
    \label{alg4:s}
\end{algorithm}


% Max-pool loop
The next step is the graph matching algorithm is the max-pool loop presented in \cite{cho_finding_2014}. We initialize the similarity matrix as ones $X^* \in 1^{bs\times n \times n}$ with $bs$ denoting the batch size. For a certain number of iterations, Cho \textit{et al.} proposes $40$ but the number should be adjusted to the number of nodes in the graph, we multiply $X^*$ with a reduced version of $S$ and use its Frobenius norm as normalizer. The algorithm \ref{alg4:maxpool} shows our implementation for batches.


\begin{algorithm}
    \caption{Max-pool graph matching for batches}
    \hspace*{\algorithmicindent} \textbf{Input:} $(S_r, S_e)$
    \begin{algorithmic}[1]
        \State Init $X^* \in 1^{bs\times n \times n}$
        \For{$iteration=1,2,\dots$}
            \State $S_{max} = \operatorname{sum}(\operatorname{max}(S_r \odot X^*\operatorname{.unsqueeze}([1,1])))$ \Comment{Sum and max over the last dimension. Unsqueeze two times on the second dimension}
            \State $X^* = X^* \odot S_e + S_{max}$
            \State $X^* = X^* / \operatorname{frobenius\_norm}(X^*$)
        \EndFor
        \State \textbf{return} $X^*$
    \end{algorithmic}
    \label{alg4:maxpool}
\end{algorithm}


To the best of our knowledge, this is the first time this algorithm is implemented in batch style. Thus, we would like to believe that laying out the implementation in detail will contribute to the academic value of this thesis.  

% Hungarian
The last step in the graph matching pipeline is the discretization of $X^*$. We adopt Simonovsky's \cite{simonovsky_graphvae_2018} approach which for this purpose uses the Hungarian algorithm as presented in \ref{ssec3:hung}. To our disappointment and resulting in a bottleneck, no batch nor tensor implementation of the named algorithm has been published so far. Thus, we convert $X^*$ to \texttt{numpy.array()} format and make use of the \textit{Scipy} package \cite{2020SciPy-NMeth}. First we create the cost matrix $X_{cost} = 1 - X^*$ and then, iterating over the batch size, use \texttt{scipy.optimize.linear\_sum\_assignment} which returns the optimal assignment matrix. This is our final permutation matrix $X$, indicating the best match between target and prediction. If no permutation is needed, $X$ is the identity matrix of $A$.


% %  explain the code
% % batch implementation
% % loop implementation to check
% Summing over the neighbors means summing over the whole column
% Normalize matrix with Frobenius Norm

% Batch version:
% Only matmul and dot. keep dimension of S with shape (bs,n,n,k,k)
% When maxpooling, flatten Xs (n,k) for batch dot multiplication. This way (i think) we sum over all j nad b neighbors instead of taking the max.  

\subsubsection{Loss function}
\label{ssec4:loss}

The RGVAE uses the ELBO loss from equation \ref{eq3:elbo}, consisting of two terms, the regularization loss and the reconstruction loss. We will present our implementation of both loss terms with graph matching and an alternative loss without graph matching for comparative evaluation of our results 


TODO derive why A is permuted on target (BCE) and E and F on prediction (Categorical) when $n \neq k$.

%  reconstruction ref to loss
%  point out challenges, log, nan
We implement $\log p\left(A^{\prime} \mid \mathbf{z}\right)$ from equation \ref{eq3:GAVElossA} with the second normalizing constant as $1 / k*K$ since we allow self-loops. The permutation matrix $X$ is applied to to the target adjacency, resulting in $A^{\prime}$. For $\log p\left(E^{\prime} \mid \mathbf{z}\right)$ and $\log p\left(F \mid \mathbf{z}\right)$ the permutation is applied to the prediction, which in the case of $E^\prime$ requires our own implementation of matrix multiplication of $d>2$ . Taking into account self-loops we change the normalization constant of $\log p\left(E^{\prime} \mid \mathbf{z}\right)$ to $1 /\left(\|A\|_{1}\right)$. It is left to mention that when implementing $\sum_{i \neq j} \log E_{i, j,}^{T}, \widetilde{E}_{i, j, \cdot}^{\prime}$ in matrix multiplication style, we have to account for the zero values before taking the logarithm. We implement \texttt{torch.sum(torch.sum(torch.log(no\_zero($E$ * $\hat{E}$)),-1)-1)} with \texttt{no\_zero()} being a function which replaces $0$ values with $1$. This implementation of the loss function can be backpropageted with exception of the graph matching part, where the \texttt{numpy} implementation of the hungarian algorithm prevents backpropagation.

% regularization loss + beta
The regularization loss is given by the KL divergence between the approximated posterior $\log q_{\phi}\left(\mathbf{z} \mid \mathbf{x}\right)$ and the Gaussian prior $p(\mathbf{z})$. The only modification we make to the original loss, is adding a $\beta$ parameter which in values $100<\beta <500$ has shown great results in factorizing the latent space \cite{higgins_beta-vae_2016}. By setting $\beta=1$ we return to the original loss function. This hyperparameter will be explored in the experiments.


% present loss function w/o graph matching 
Alternatively and as ground truth we implement the VAE loss from equation \ref{eq3:elbo} for graphs without graph matching. we use binary cross entropy ($BCE$) as reconstruction loss of the adjacency,  and categorical cross entropy ($CE$) for the attribute matrices. The regularization loss is similar to the above presented and also includes the hyperparameter $\beta$. The equation for the ELBO with $\sigma()$ indicating Sigmoid activation is

\begin{equation}
    \mathcal{L}(\phi,\theta:G) = BCE(A,\sigma(\tilde{A})) + CC(E,\tilde{E}) + CC(F,\tilde{F}) - D_{K L}\left(q_{{\phi}}\left(\mathbf{z} \mid G\right) \| p_{{\theta}}(\mathbf{z})\right)
    \label{eg4:normalELBO}
\end{equation}

We train the model on the negative ELBO. Further we use \textit{Ranger} presented in \ref{sec3:ranger} as optimizer combining three learning optimization methods. Out of the various optimization parameters, we achived good performance with the default values and  only adjusted the learning rate and the number of lookahead steps. Missing a publication to cite, we refer to the source code \textit{Ranger} \footnote{\url{https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer}}


% optimizer ranger github repo link

\subsection{Link prediction and Metrics}
\label{ssec4:lpmetrics}
% LP as main experiment and proof of concept. 
Our first experiment is link prediction, which we assume will give an insight in the models capacity to reproduce the data. It is intended as proof of concept rather than an attempt to set the state of the art. The results will let us draw conclusions on the impact and function of different parameters.
Besides the final link prediction experiment, we will let the model perform link prediction on a randomly drawn small subset of the test set during training. This gives us a broader view on the models performance, which otherwise would only be evaluated by the ELBO loss.  

% describe LP as in paper OLD DOG
Link prediction on multi-relational KGs is the task of predicting unobserved triples, based on the information gained from the trainings data. To evaluate a model on this task, the most common method is entity ranking in the form of triple completion of unseen triples from the test set. Given a KG $G(\mathcal{E},\mathcal{V})$ we want our model find the right entity out of $\mathcal{E}$ which completes the unseen triple $(s,r,?)$ or $(?,r,o)$ for heads or tail prediction. Thus, the model scores the triple for all possible combination with the entities from $\mathcal{E}$. The rank of the true triple, in descending order, defines the performance of the model \cite{ruffinelli_you_2019}.

In the preprocessing step we created a dictionary with all occurring combinations for all possible triples with missing head or tail. These dictionaries we use to filter out real triples from the scoring. Unfiltered scores are referred to as raw scores. Per link prediction run, the model has to score the number of triples in the test set times the $d_e$ the number of entities in $\mathcal{E}$ times two for head and tail, which mostly results in a number much larger than the size of the actual dataset.

Finally, the metrics for link prediction are the mean reciprocal rank (MRR) of the score for the true triple and the average HITS@$k$ with $k \in [1,3,10]$. We denote $\mathcal{K}_{test}$ the unseen test set and $\left|\mathcal{K}_{\text {test }}\right|$ the number of triples in the test set. The operator $\operatorname{rank()}$ returns the in descending order the by the model scored position of the true triple. Head prediction of a triple given relation and object is denoted $(s|r,o)$ and likewise $(o|s,r)$ for tail prediction. The Iverson brackets $[\operatorname{rank}(s \mid r, o) \leq k]$ return $1$ if the scored rank is equal or lower than $k$, else $o$. 
% describe MRR, Hits at n


\begin{equation}
    \begin{aligned}
    \operatorname{MRR} &=\frac{1}{2\left|\mathcal{K}_{\text {test }}\right|} \sum_{(s, r, o) \in \mathcal{K}_{\text {lest }}}\left(\frac{1}{\operatorname{rank}(s \mid r, o)}+\frac{1}{\operatorname{rank}(o \mid s, r)}\right) \\
    \text { Hits@ } k &=\frac{1}{2\left|\mathcal{K}_{\text {test }}\right|} \sum_{(s, r, o) \in \mathcal{k}_{\text {lest }}}(\mathbb{1}[\operatorname{rank}(s \mid r, o) \leq k]+\mathbb{1}[\operatorname{rank}(o \mid s, r) \leq k])
    \end{aligned}
\label{eq4:MRR}
\end{equation}
% mention we use MRR during training on subset


% Link prediction to make a proof of concept, not achieve SOTA.\\

% First:
% Node classifier by only using encoder.\\
% latent space interpolation to find analogies to smile vector in the latent space of a face VAEs.\\
% Identify if VAE learns semantics. OWL, onthology datasetbatch_size, required.\\
% Wasserstein distance???
% Link prediction?


% \begin{itemize}
%     \item Load Dataset
%     \item Convert to sparse in batches
%     \item forward pass through VAE
%     \item MPGM loss
%     \item Backward pass
%     \item test on val set
%     \item calculate MRR on subset of val set
%     \item draw graphs
% \end{itemize}


\subsection{Variational DistMult}
\label{ssec4:vdistm}

% why do we implement it, which variation
In the context of link prediction, we implement control model for better interpretability of our results. From the wide range of embedding based models, DistMult reports both good results as well as an efficient architecture. Its bilinear property aligns with the permutation invariance of the RGVAE. Based the original model we implement a variational version of DistMult to isolate the effect of variational inference on multi-relational link prediction.

% architecture link to embed
The DistMult encoder has a linear embedding layer for both sets of entities and relations. The embedded or latent representation is passed through the bilinear scoring function, which is equation \ref{eq2:distmult}. During training the model scores the triples in the training set among a number of corrupted triples. Loss function and optimizer are tunable hyperparameter. The optimal hyperparameter settings for the FB15k-237 dataset are published in Ruffellini \textit{et al.} \cite{ruffinelli_you_2019} and will be the used for our link prediction experiment.

% option to train with elbo or just scores
The model implementation is adopted from Peter Bloem's work \footnote{\url{https://github.com/pbloem/embed}}. Additionally a variational module is implemented, which uses the embedding vector representation as mean and logvariance for a latent distribution from where the latent representation is sampled using the reparametrization trick. When this method is not selected, the stochastic coefficient $\epsilon$ is set to $1$ rather than a random sample from the standard normal distribution. Lastly we implement the ELBO loss, which adds a regularization term, including $\beta$ parameters to the BCE loss, thus we can only use the variational DistMult (VDistMult) in combination with BCE loss. The scoring function of the VDistMult stays identical to the original. We use the parameter settings for both the original and the variational DistMult. 

% optimal parameters

% Control model
% reparametrization trick in middle
% still same scoring function

