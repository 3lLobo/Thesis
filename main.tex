% !BIB program = bibtex
\documentclass{article}

\usepackage{graphicx, color}

\usepackage[a4paper,margin=2cm]{geometry}

% Here are my package imports:
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{layouts}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multirow}
\usepackage{pdfpages}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{svg}
\usepackage[T1]{fontenc}
\usepackage{pdfpages}

\setlength{\parindent}{3em}
% \setlength{\parskip}{1em}
\newcommand{\red}[1]{{\color{red}{#1}}}

\RequirePackage[backend=bibtex,style=nature]{biblatex}

\addbibresource{fullrefs.bib}

\begin{document}




\begin{titlepage}



\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

 

%----------------------------------------------------------------------------------------

%	HEADING SECTIONS

%----------------------------------------------------------------------------------------



\includegraphics[width=\linewidth]{data/images/uvaENG}\\[2.5cm]

\textsc{\Large MSc Artificial Intelligence}\\[0.2cm]

\textsc{\Large Master Thesis}\\[0.5cm] 



%----------------------------------------------------------------------------------------

%	TITLE SECTION

%----------------------------------------------------------------------------------------



\HRule \\[0.4cm]

{ \huge \bfseries Knowledge Generation \\ \Large Variational Bayes on Knowledge Graphs \\ [0.4cm] } % Title of your document

\HRule \\[0.5cm]

 

%----------------------------------------------------------------------------------------

%	AUTHOR SECTION

%----------------------------------------------------------------------------------------



by\\[0.2cm]

\textsc{\Large Florian Wolf}\\[0.2cm] %you name

{12393339}\\[1cm]





%----------------------------------------------------------------------------------------

%	DATE SECTION

%----------------------------------------------------------------------------------------



{\Large \today}\\[1cm] % Date, change the \today to a set date if you want to be precise



{48 Credits}\\ %
{April 2020 - January 2021}\\[1cm]
%{Period in which the research was carried out}\\[1cm]%



%----------------------------------------------------------------------------------------

%	COMMITTEE SECTION

%----------------------------------------------------------------------------------------

\begin{minipage}[t]{0.4\textwidth}

\begin{flushleft} \large

\emph{Supervisor:} \\

Dr Peter \textsc{Bloem} \\ Thiviyan \textsc{Thanapalasingam} \\ Chiara \textsc{Spruijt} % Supervisor's Name

\end{flushleft}

\end{minipage}

~

\begin{minipage}[t]{0.4\textwidth}

\begin{flushright} \large

\emph{Asessor:} \\

Dr Paul \textsc{Groth}\\

\end{flushright}

\end{minipage}\\[2cm]



%----------------------------------------------------------------------------------------

%	LOGO SECTION

%----------------------------------------------------------------------------------------



% \framebox{\rule{0pt}{2.5cm}\rule{2.5cm}{0pt}}\\[0.5cm]

\includegraphics[width=2.5cm]{data/images/uva.png}\\ % Include a department/university logo - this will require the graphicx package

% \textsc{\large \red{institute name}}\\[1.0cm] % 

 

%----------------------------------------------------------------------------------------



\vfill % Fill the rest of the page with whitespace



\end{titlepage}

\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage

\section*{Abstract}
% We generate Knowledge! \cite{kipf_contrastive_2020}

This thesis aims to be a proof of concept for the potential of Variational Auto-Encoder on representation learning of real-world Knowledge Graphs (KG). Building on successful approaches in the field of molecular graphs, we experiment and evaluate the capabilities and limitation of our model, the relational graph Variational Auto-Encoder (RGVAE), characterized by its permuation invariant loss function. The impact of the modular choices, encoding though convolutions, graph matching and latent space prior, are analyzed and the added value compared. A common criteria in the filed of KGs is link prediction, the task of completing a corrupted triple. We rank the performance of the RGVAE on link prediction in the leaderboard of the two popular datasets FB15K-237 and WN18RR, which is led by embedding based models. To isolate causalities, a variational embedding based model and a RGVAE without latent space prior constrain are implemented. We conclude, that neither convolutions nor permutation invariance alter the scoring. The results show that for exception of the RGVAE with relaxed latent space, the RGVAE does not qualify as link predictor. Furthermore its complexity does not scale to the advantages over the much simpler embedding based solution with lower parameter count.
Graph VAE on molecular data have shown promising results on interpolation of the latent space, an experiment where either the distance between the latent representation of two triples is linearly interpolated, or the full latent space is explored in a $95$\% confidence interval its distribution. On image data, VAE have been successful assigning each latent dimension to data characterising features. Both interpolation experiments show that the RGVAE learns to reconstruct the adjacency but fails to disentangle and assign the right node and edge attributes. The assumption of an uninformative latent representation is confirmed in the last experiment, for which we present a novel validation method for generated triples from the FB15K-237 dataset. The relation type-constrains of generated triples are filtered and matched with entity types. We observe that the rate of valid generated triples does vary little from the random threshold, while all generated triples are unseen in both train and test set. A comparison between different latent space priors via the $\delta$-VAE method, reveals insights in the behavior of the RGVAE's parameter distribution and its impact on the interpolation of the latent space. Finally we analyze the limitations of our approach compared to molecule generation and propose advanced solutions for successful representation learning of multi-relational KGs. 


\newpage
% \section*{Notes}
% \input{notes}

\section{Introduction}
\input{sections/section1}

\section{Related Work}
\input{sections/section2}

\section{Background}
\input{sections/section3}

\section{Methods}
\input{sections/section4}
\label{sec:mthods}

\section{Experiments \& Results}
\input{sections/section5}

% \section{Results}
% \input{sections/section6}

\section{Discussion \& Future Work}
\input{sections/section7}
\label{sec:discus}

% \section*{Ideas}
% \input{ideas}

% \section*{Open Issues}
% \input{issues}

\newpage
\printbibliography
\end{document}

% \bibliographystyle{unsrt} % We choose the "plain" reference style
% \bibliography{fullrefs} % Entries are in the "refs.bib" file

